{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4e175e-2876-4e23-910a-6444b3d9c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Укажите путь к вашим CSV-файлам (например, если они находятся в папке \"data\")\n",
    "#all_files = glob.glob(r'C:\\Users\\Гребенников Матвей\\Desktop\\Диплом\\Диплом\\GeneratedLabelledFlows\\TrafficLabelling/*.csv')\n",
    "\n",
    "# Читаем все файлы в список DataFrame\n",
    "#df_list = [pd.read_csv(file, encoding='cp1252', low_memory=False) for file in all_files]\n",
    "\n",
    "\n",
    "# Объединяем все DataFrame в один общий DataFrame\n",
    "#combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Удаляем лишние пробелы в названиях столбцов\n",
    "#combined_df.columns = combined_df.columns.str.strip()\n",
    "\n",
    "# Теперь combined_df можно использовать для предобработки\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Преобразует DataFrame в список транзакций.\n",
    "    Каждая транзакция – это список строк вида \"ИмяСтолбца:Значение\".\n",
    "    Используются столбцы: Timestamp, Source IP, Source Port, Destination IP, \n",
    "    Destination Port, Protocol, Label.\n",
    "    \"\"\"\n",
    "    transactions = []\n",
    "    selected_columns = [ 'Total Fwd Packets','Flow Duration', 'Destination Port', 'Protocol', 'Label']\n",
    "    for index, row in df.iterrows():\n",
    "        transaction = []\n",
    "        for col in selected_columns:\n",
    "            value = str(row[col])\n",
    "            item = f\"{col}:{value}\"\n",
    "            transaction.append(item)\n",
    "        transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "# Используем объединённый DataFrame для формирования транзакций\n",
    "#transactions = preprocess_data(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b55789-192b-476e-91e7-01c4314c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс узла FP-дерева\n",
    "class FPNode:\n",
    "    def __init__(self, item, count, parent):\n",
    "        self.item = item          # Например, \"Protocol:TCP\"\n",
    "        self.count = count        # Подсчет вхождений\n",
    "        self.parent = parent      # Родительский узел\n",
    "        self.children = {}        # Дочерние узлы: {элемент: FPNode}\n",
    "        self.node_link = None     # Ссылка на следующий узел с таким же элементом\n",
    "\n",
    "    def increment(self, count):\n",
    "        self.count += count\n",
    "\n",
    "def update_tree(items, tree, header_table, count):\n",
    "    \"\"\"\n",
    "    Рекурсивно добавляет отсортированный список элементов в FP-дерево.\n",
    "    Если элемент уже присутствует – увеличивает его счётчик, иначе создаёт новый узел.\n",
    "    \"\"\"\n",
    "    first_item = items[0]\n",
    "    if first_item in tree.children:\n",
    "        tree.children[first_item].increment(count)\n",
    "    else:\n",
    "        new_node = FPNode(first_item, count, tree)\n",
    "        tree.children[first_item] = new_node\n",
    "        # Обновляем заголовочную таблицу: если узел отсутствует, записываем его,\n",
    "        # иначе добавляем в цепочку через node_link.\n",
    "        if header_table[first_item][1] is None:\n",
    "            header_table[first_item][1] = new_node\n",
    "        else:\n",
    "            current = header_table[first_item][1]\n",
    "            while current.node_link is not None:\n",
    "                current = current.node_link\n",
    "            current.node_link = new_node\n",
    "    if len(items) > 1:\n",
    "        update_tree(items[1:], tree.children[first_item], header_table, count)\n",
    "\n",
    "def create_fp_tree(transactions, min_support):\n",
    "    \"\"\"\n",
    "    Создает FP-дерево из транзакций:\n",
    "      1. Подсчитывает поддержку каждого элемента.\n",
    "      2. Отбрасывает элементы с поддержкой ниже min_support.\n",
    "      3. Формирует заголовочную таблицу: {элемент: [поддержка, ссылка на первый узел]}.\n",
    "      4. Для каждой транзакции оставляет только частые элементы, сортирует их по убыванию поддержки \n",
    "         и рекурсивно добавляет в дерево.\n",
    "    \"\"\"\n",
    "    freq = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            freq[item] = freq.get(item, 0) + 1\n",
    "    freq = {item: count for item, count in freq.items() if count >= min_support}\n",
    "    if not freq:\n",
    "        return None, None\n",
    "    header_table = {item: [count, None] for item, count in freq.items()}\n",
    "    root = FPNode('Null', 1, None)\n",
    "    for transaction in transactions:\n",
    "        transaction_items = [item for item in transaction if item in freq]\n",
    "        if transaction_items:\n",
    "            sorted_items = sorted(transaction_items, key=lambda item: header_table[item][0], reverse=True)\n",
    "            update_tree(sorted_items, root, header_table, 1)\n",
    "    return root, header_table\n",
    "\n",
    "def ascend_fp_tree(node):\n",
    "    \"\"\"\n",
    "    Поднимается по дереву от узла до корня (не включая корень)\n",
    "    и возвращает список элементов пути.\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    while node.parent is not None and node.parent.item != 'Null':\n",
    "        node = node.parent\n",
    "        path.append(node.item)\n",
    "    return path\n",
    "\n",
    "def find_prefix_paths(base_item, header_table):\n",
    "    \"\"\"\n",
    "    Находит условную базу (prefix pattern base) для base_item.\n",
    "    Возвращает словарь: {frozenset(пути): count}\n",
    "    \"\"\"\n",
    "    conditional_patterns = {}\n",
    "    node = header_table[base_item][1]\n",
    "    while node:\n",
    "        prefix_path = ascend_fp_tree(node)\n",
    "        if prefix_path:\n",
    "            conditional_patterns[frozenset(prefix_path)] = node.count\n",
    "        node = node.node_link\n",
    "    return conditional_patterns\n",
    "\n",
    "def mine_fp_tree(tree, header_table, min_support, pre_fix, frequent_itemsets):\n",
    "    \"\"\"\n",
    "    Рекурсивно добывает частые наборы элементов из FP-дерева.\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(header_table.items(), key=lambda x: x[1][0])\n",
    "    for base_item, base_info in sorted_items:\n",
    "        new_freq_set = pre_fix.copy()\n",
    "        new_freq_set.add(base_item)\n",
    "        frequent_itemsets[frozenset(new_freq_set)] = base_info[0]\n",
    "        conditional_patterns = find_prefix_paths(base_item, header_table)\n",
    "        conditional_transactions = []\n",
    "        for path, count in conditional_patterns.items():\n",
    "            for _ in range(count):\n",
    "                conditional_transactions.append(list(path))\n",
    "        if conditional_transactions:\n",
    "            conditional_tree, conditional_header = create_fp_tree(conditional_transactions, min_support)\n",
    "            if conditional_header is not None:\n",
    "                mine_fp_tree(conditional_tree, conditional_header, min_support, new_freq_set, frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394ea462-c1ae-4170-b898-7c0e264cf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(frequent_itemsets, min_conf):\n",
    "    \"\"\"\n",
    "    Для каждого частого набора генерирует правила A -> B, \n",
    "    но оставляет только те, в которых B состоит исключительно из меток (Label:...).\n",
    "    Рассчитывает достоверность: conf = support(A ∪ B) / support(A)\n",
    "    Если conf >= min_conf, правило добавляется.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        # Перебираем все непустые подмножества itemset\n",
    "        for subset in chain.from_iterable(combinations(itemset, r) for r in range(1, len(itemset))):\n",
    "            A = set(subset)\n",
    "            B = set(itemset) - A\n",
    "            # Ограничиваем правила: оставляем только те, где все элементы B начинаются с \"Label:\"\n",
    "            if B and all(item.startswith(\"Label:\") for item in B) and frozenset(A) in frequent_itemsets:\n",
    "                conf = frequent_itemsets[frozenset(itemset)] / frequent_itemsets[frozenset(A)]\n",
    "                if conf >= min_conf:\n",
    "                    rules.append((A, B, conf, frequent_itemsets[frozenset(itemset)]))\n",
    "    return rules\n",
    "\n",
    "\n",
    "def improved_fp_growth(transactions, min_sup, min_conf):\n",
    "    \"\"\"\n",
    "    Улучшенный FP-growth объединяет:\n",
    "      - Построение FP-дерева.\n",
    "      - Добычу частых наборов (mine_fp_tree).\n",
    "      - Генерацию ассоциативных правил.\n",
    "    Возвращает frequent_itemsets и правила.\n",
    "    \"\"\"\n",
    "    fp_tree, header_table = create_fp_tree(transactions, min_sup)\n",
    "    frequent_itemsets = {}\n",
    "    if fp_tree:\n",
    "        mine_fp_tree(fp_tree, header_table, min_sup, set(), frequent_itemsets)\n",
    "    rules = generate_association_rules(frequent_itemsets, min_conf)\n",
    "    return frequent_itemsets, rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613d0ff1-5352-45af-8363-2f6293bdbb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для COFI‑дерева создаём отдельные классы и функции, чтобы не было конфликта с FP-деревом.\n",
    "\n",
    "class COFINode:\n",
    "    def __init__(self, item, count, parent):\n",
    "        self.item = item                # Например, \"Protocol:6\"\n",
    "        self.count = count              # Подсчет вхождений\n",
    "        self.parent = parent            # Родительский узел\n",
    "        self.children = {}              # Дочерние узлы: {элемент: COFINode}\n",
    "        self.node_link = None           # Ссылка на следующий узел с таким же элементом\n",
    "        self.participation_counter = 0  # Дополнительный счетчик (при необходимости)\n",
    "\n",
    "    def increment(self, count):\n",
    "        self.count += count\n",
    "\n",
    "def update_cofi_tree(items, tree, header_table, count):\n",
    "    first_item = items[0]\n",
    "    if first_item in tree.children:\n",
    "        tree.children[first_item].increment(count)\n",
    "    else:\n",
    "        new_node = COFINode(first_item, count, tree)\n",
    "        tree.children[first_item] = new_node\n",
    "        if header_table[first_item][1] is None:\n",
    "            header_table[first_item][1] = new_node\n",
    "        else:\n",
    "            current = header_table[first_item][1]\n",
    "            while current.node_link:\n",
    "                current = current.node_link\n",
    "            current.node_link = new_node\n",
    "    if len(items) > 1:\n",
    "        update_cofi_tree(items[1:], tree.children[first_item], header_table, count)\n",
    "\n",
    "def create_cofi_tree_cofi(transactions, min_support):\n",
    "    \"\"\"\n",
    "    Создает COFI‑дерево из транзакций (отдельная функция для COFI‑дерева).\n",
    "    \"\"\"\n",
    "    freq = {}\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            freq[item] = freq.get(item, 0) + 1\n",
    "    freq = {item: count for item, count in freq.items() if count >= min_support}\n",
    "    if not freq:\n",
    "        return None, None\n",
    "    header_table = {item: [count, None] for item, count in freq.items()}\n",
    "    root = COFINode('Null', 1, None)\n",
    "    for transaction in transactions:\n",
    "        transaction_items = [item for item in transaction if item in freq]\n",
    "        if transaction_items:\n",
    "            sorted_items = sorted(transaction_items, key=lambda item: header_table[item][0], reverse=True)\n",
    "            update_cofi_tree(sorted_items, root, header_table, 1)\n",
    "    return root, header_table\n",
    "\n",
    "def build_cofi_tree_for_item(base_item, fp_header, min_support):\n",
    "    \"\"\"\n",
    "    Извлекает условную базу (prefix pattern base) для base_item из FP-дерева\n",
    "    и строит COFI‑дерево для этих транзакций.\n",
    "    \"\"\"\n",
    "    conditional_patterns = find_prefix_paths(base_item, fp_header)\n",
    "    cofi_transactions = []\n",
    "    for path, count in conditional_patterns.items():\n",
    "        for _ in range(count):\n",
    "            cofi_transactions.append(list(path))\n",
    "    return create_cofi_tree_cofi(cofi_transactions, min_support)\n",
    "\n",
    "def mine_cofi_tree(tree, header_table, min_support, pre_fix, cofi_patterns):\n",
    "    \"\"\"\n",
    "    Рекурсивно добывает частые наборы элементов из COFI‑дерева.\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(header_table.items(), key=lambda x: x[1][0])\n",
    "    for base_item, base_info in sorted_items:\n",
    "        new_freq_set = pre_fix.copy()\n",
    "        new_freq_set.add(base_item)\n",
    "        cofi_patterns[frozenset(new_freq_set)] = base_info[0]\n",
    "        conditional_patterns = find_prefix_paths(base_item, header_table)\n",
    "        conditional_transactions = []\n",
    "        for path, count in conditional_patterns.items():\n",
    "            for _ in range(count):\n",
    "                conditional_transactions.append(list(path))\n",
    "        if conditional_transactions:\n",
    "            conditional_tree, conditional_header = create_cofi_tree_cofi(conditional_transactions, min_support)\n",
    "            if conditional_header is not None:\n",
    "                mine_cofi_tree(conditional_tree, conditional_header, min_support, new_freq_set, cofi_patterns)\n",
    "\n",
    "def build_sd_structure(cofi_patterns, min_support):\n",
    "    \"\"\"\n",
    "    Группирует наборы из COFI‑дерева по длине и корректирует их поддержку.\n",
    "    Для каждого набора меньшей длины ищутся наборы с большей длиной, содержащие его,\n",
    "    и поддержка увеличивается.\n",
    "    \"\"\"\n",
    "    sd_segments = {}\n",
    "    for pattern, support in cofi_patterns.items():\n",
    "        length = len(pattern)\n",
    "        sd_segments.setdefault(length, []).append((pattern, support))\n",
    "    \n",
    "    updated_patterns = {}\n",
    "    for length in sorted(sd_segments.keys()):\n",
    "        for pattern, support in sd_segments[length]:\n",
    "            updated_support = support\n",
    "            for longer_length in sorted(sd_segments.keys()):\n",
    "                if longer_length > length:\n",
    "                    for longer_pattern, longer_support in sd_segments[longer_length]:\n",
    "                        if pattern.issubset(longer_pattern):\n",
    "                            updated_support += longer_support\n",
    "            updated_patterns[pattern] = updated_support\n",
    "    \n",
    "    final_patterns = {pattern: sup for pattern, sup in updated_patterns.items() if sup >= min_support}\n",
    "    return final_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50707745-ccda-4986-89a2-ba1dbf763876",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:33\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных CICIDS 2017 и предобработка\n",
    "#transactions = preprocess_data(combined_df)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\Гребенников Матвей\\Desktop\\Диплом\\Диплом\\GeneratedLabelledFlows\\TrafficLabelling\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "transactions = preprocess_data(df)\n",
    "\n",
    "# Задаем параметры: минимальный порог поддержки и достоверности\n",
    "min_support = 10\n",
    "min_conf = 0.8\n",
    "\n",
    "# 1. Построение FP-дерева (MDFP) и добыча частых наборов\n",
    "fp_tree, header_table = create_fp_tree(transactions, min_support)\n",
    "frequent_itemsets = {}\n",
    "if fp_tree is None:\n",
    "    print(\"Нет частых элементов, удовлетворяющих min_support.\")\n",
    "else:\n",
    "    mine_fp_tree(fp_tree, header_table, min_support, set(), frequent_itemsets)\n",
    "    print(\"Частые наборы (MDFP):\")\n",
    "    for itemset, support in sorted(frequent_itemsets.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(set(itemset), \"поддержка:\", support)\n",
    "\n",
    "    # 2. Улучшенный FP-growth (объединяет этапы из 4.3)\n",
    "    freq_itemsets_improved, association_rules = improved_fp_growth(transactions, min_support, min_conf)\n",
    "    print(\"\\nЧастые наборы (улучшенный FP-growth):\")\n",
    "    for itemset, support in sorted(freq_itemsets_improved.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(set(itemset), \"поддержка:\", support)\n",
    "        \n",
    "    print(\"\\nАссоциативные правила (min_conf = {}):\".format(min_conf))\n",
    "    for A, B, conf, sup in association_rules:\n",
    "        print(f\"{A} -> {B} (conf: {conf:.2f}, support: {sup})\")\n",
    "    \n",
    "\n",
    " # 3. Применение COFI-дерева и структуры SD:\n",
    "    # Используем несколько базовых элементов \n",
    "    base_items = [\n",
    "    \"Label:BENIGN\",\n",
    "    \"Label:DDoS\",            # если есть такие метки\n",
    "    \"Label:PortScan\",       # если есть такие метки\n",
    "    \"Protocol:6\",           # TCP\n",
    "    \"Protocol:17\",          # UDP\n",
    "    \"Destination Port:80\",\n",
    "    \"Destination Port:443\",\n",
    "    \"Destination Port:53\",\n",
    "    \"Protocol:6\",\n",
    "    \"Protocol:17\",\n",
    "    \"Protocol:1\"\n",
    "                 ]\n",
    "    all_cofi_patterns = {}\n",
    "    for base_item in base_items:\n",
    "        if base_item in header_table:\n",
    "            # Строим COFI-дерево по транзакциям, где содержится base_item\n",
    "            cofi_tree, cofi_header = create_cofi_tree_cofi([t for t in transactions if base_item in t], min_support)\n",
    "            if cofi_tree and cofi_header:\n",
    "                cofi_patterns = {}\n",
    "                mine_cofi_tree(cofi_tree, cofi_header, min_support, pre_fix=set([base_item]), cofi_patterns=cofi_patterns)\n",
    "                print(f\"\\nЧастые наборы из COFI-дерева для {base_item}:\")\n",
    "                for itemset, support in sorted(cofi_patterns.items(), key=lambda x: x[1], reverse=True):\n",
    "                    print(set(itemset), \"поддержка:\", support)\n",
    "                all_cofi_patterns.update(cofi_patterns)\n",
    "            else:\n",
    "                print(f\"\\nНет условных транзакций для {base_item} с min_support = {min_support}.\")\n",
    "        else:\n",
    "            print(f\"\\nЭлемент {base_item} не найден в FP-дереве.\")\n",
    "    \n",
    "    print(\"\\n--- Применение структуры SD ко всем полученным наборам ---\")\n",
    "    sd_patterns = build_sd_structure(all_cofi_patterns, min_support)\n",
    "    for pattern, support in sorted(sd_patterns.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(set(pattern), \"поддержка:\", support) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cfb80-444c-4bb0-8789-279cf2b3085d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
